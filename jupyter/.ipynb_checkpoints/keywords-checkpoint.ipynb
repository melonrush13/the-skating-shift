{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook Summary\n",
    "\n",
    "# This notebook performs the following:\n",
    "# - Scrapes all individual words from tweets in \"rollerskating\" tweets in 2020\n",
    "# - Analysizes other popular keywords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28985 entries, 0 to 28984\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   datetime  28985 non-null  object\n",
      " 1   tweet_id  28985 non-null  int64 \n",
      " 2   text      28985 non-null  object\n",
      " 3   username  28985 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 905.9+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read 2020 \"Rollerskating\" Scrapped Data\n",
    "datafile = \"..//scraped_tweets/2020_snscrape_tweets.csv\"\n",
    "data = pd.read_csv(datafile)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/melanierush/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/melanierush/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /Users/melanierush/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need NLTK corpora\n",
    "from nltk import corpus\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rollerskating', 13418),\n",
       " ('https', 10992),\n",
       " ('the', 6384),\n",
       " ('to', 6156),\n",
       " ('I', 5599),\n",
       " ('a', 5071),\n",
       " ('and', 4819),\n",
       " ('in', 3075),\n",
       " ('of', 2974),\n",
       " ('’', 2736)]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data['text'])\n",
    "\n",
    "covidNounPhrasesArr = []\n",
    "covidTagsArr = []\n",
    "covidTweets = []\n",
    "covidWordsArr = []\n",
    "allWords2020 = []\n",
    "\n",
    "for tweet in df['text']:\n",
    "    #if tweets contain COVID\n",
    "    if tweet.find(\"covid\") >= 0:\n",
    "        \n",
    "        # Textblob analysis\n",
    "        blob_object = TextBlob(tweet)\n",
    "        blob = TextBlob(tweet)\n",
    "        words = blob_object.words\n",
    "\n",
    "        # put tags in Arr\n",
    "        covidTagsArr.append(blob.tags)\n",
    "        # put NounPhrases in Arr\n",
    "        covidNounPhrasesArr.append(blob.noun_phrases)\n",
    "        # put covidTweets in Arr\n",
    "        covidTweets.append(tweet)\n",
    "        \n",
    "        # build clean Arr of individual words\n",
    "        for word in words:\n",
    "            covidWordsArr.append(word)\n",
    "   \n",
    "    # all tweets\n",
    "    blob_object = TextBlob(tweet)\n",
    "    words = blob_object.words\n",
    "        \n",
    "    for word in words:\n",
    "        allWords2020.append(word)\n",
    "        \n",
    "\n",
    "c = Counter(allWords2020)\n",
    "c.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words\n",
      "357804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('rollerskating', 13418),\n",
       " ('https', 10992),\n",
       " ('the', 6384),\n",
       " ('to', 6156),\n",
       " ('I', 5599),\n",
       " ('a', 5071),\n",
       " ('and', 4819),\n",
       " ('in', 3075),\n",
       " ('of', 2974),\n",
       " ('’', 2736)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Total Words\")\n",
    "print(len(allWords2020))\n",
    "c.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moxi  34\n",
      "bought  25\n",
      "purchased  5\n",
      "buy  29\n",
      "want  492\n",
      "need  232\n",
      "love  624\n",
      "hate  32\n",
      "mad  28\n",
      "derby  153\n",
      "hobby  34\n"
     ]
    }
   ],
   "source": [
    "print(\"moxi \", c['moxi'])\n",
    "print(\"bought \", c['bought'])\n",
    "print(\"purchased \", c['purchased'])\n",
    "print(\"buy \", c['buy'])\n",
    "print(\"want \", c['want'])\n",
    "print(\"need \", c['need'])\n",
    "print(\"love \", c['love'])\n",
    "print(\"hate \", c['hate'])\n",
    "print(\"mad \", c['mad'])\n",
    "print(\"derby \", c['derby'])\n",
    "print(\"hobby \", c['hobby'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
